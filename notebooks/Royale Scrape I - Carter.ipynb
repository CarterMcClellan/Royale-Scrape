{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraper\n",
    "- This part of the code handles getting the individual player information which is hosted at [Stats Royale](!https://statsroyale.com/)\n",
    "\n",
    "### Before Scraping\n",
    "**IMPORTANT** the information pulled is only as accurate as the information reflected on the website. To ensure the player information is accurate go to the player id and refresh the page\n",
    "- [Dad](!https://statsroyale.com/profile/L8RCCJGV)\n",
    "- [Carter](!https://statsroyale.com/profile/PVQ90YCV)\n",
    "- [Chris](!https://statsroyale.com/profile/2JV9RJYJG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from pandas import ExcelWriter, DataFrame\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CARTER_KEY = \"PVQ90YCV\"\n",
    "CHRIS_KEY = \"2JV9RJYJG\"\n",
    "DAD_KEY = \"L8RCCJGV\"\n",
    "\n",
    "rarities = ['Common', 'Epic', 'Legendary', 'Rare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return parsed profile page using BS4\n",
    "def parseURL(tag, sort_by):\n",
    "    if sort_by == \"level\":\n",
    "         link = \"https://statsroyale.com/profile/{}/cards?sort=level\".format(tag)\n",
    "    elif sort_by == \"elixir\":\n",
    "        link = \"https://statsroyale.com/profile/{}/cards?sort=exlixir\".format(tag)\n",
    "    elif sort_by == \"rarity\":\n",
    "        link = \"https://statsroyale.com/profile/{}/cards?sort=rarity\".format(tag)\n",
    "    elif sort_by == \"arena\":\n",
    "        link = \"https://statsroyale.com/profile/{}/cards?sort=arena\".format(tag)\n",
    "    \n",
    "    response = requests.get(link).text\n",
    "    soup = BeautifulSoup(response, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Card:\n",
    "    ''' \n",
    "    Class used to hold all the information relevant to each individual card\n",
    "    '''\n",
    "    def __init__(self, card_html):\n",
    "        self.name, self.level, self.curr_count, self.rarity = self.parse(card_html)\n",
    "    \n",
    "    def parse(self, card_html):\n",
    "        rarity_map = {\n",
    "            \"1\" : \"Common\", \n",
    "            \"2\" : \"Rare\",\n",
    "            \"3\" : \"Epic\",\n",
    "            \"4\" : \"Legendary\"\n",
    "        }\n",
    "        name = card_html.find(\"div\", {\"class\" : \"ui__tooltip ui__tooltipTop ui__tooltipMiddle cards__tooltip\"}).text.replace('\\n','')\n",
    "        level = card_html.find(\"a\").text.replace('\\n','')\n",
    "        \n",
    "        if level == \"Max Lvl\":\n",
    "            level = \"13\"\n",
    "        else:\n",
    "            level = level[4:]\n",
    "            if level == \"\":\n",
    "                level = \"0\"\n",
    "        try:\n",
    "            curr_count = card_html.find(\"div\", {\"class\" : \"profileCards__meter__numbers\"}).text.replace('\\n','')\n",
    "        except:\n",
    "            curr_count = 0 # this occurs when the user does not have the card yet\n",
    "        rarity = card_html[\"data-rarity\"][0]\n",
    "        return name, level, curr_count, rarity_map[rarity]\n",
    "    \n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"{}\".format(self.name)\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(self.name)\n",
    "\n",
    "    def to_row(self):\n",
    "        return {\"Name\" : self.name, \"Level\": self.level, \"Count\" : self.curr_count, \"Rarity\" : self.rarity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_df(key, verbose=False):\n",
    "    carter_soup = parseURL(key, \"rarity\")\n",
    "    carter_cards_html = carter_soup.findAll(\"div\", {\"class\": \"profileCards__card upgrade \"}) + \\\n",
    "                        carter_soup.findAll(\"div\", {\"class\": \"profileCards__card \"}) + \\\n",
    "                        carter_soup.findAll(\"div\", {\"class\": \"profileCards__card upgrade\"}) + \\\n",
    "                        carter_soup.findAll(\"div\", {\"class\": \"profileCards__card\"})\n",
    "\n",
    "    carter_card_objs = [Card(card_html) for card_html in carter_cards_html]\n",
    "    if verbose:\n",
    "        print(\"Found {} cards\".format(len(carter_card_objs)))\n",
    "        \n",
    "    try:\n",
    "        assert len(carter_card_objs) == len(set(carter_card_objs))\n",
    "    except AssertionError:\n",
    "        print(\"Duplicate Cards Detected and removed\")\n",
    "        carter_card_objs = list(set(carter_card_objs))\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"After duplicate detection found {} cards\".format(len(carter_card_objs)))\n",
    "\n",
    "    carter_cards = [card_obj.to_row() for card_obj in carter_card_objs]\n",
    "    df = pd.DataFrame(carter_cards); df.index = df.Name; del df[\"Name\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 198 cards\n",
      "After duplicate detection found 198 cards\n",
      "Found 197 cards\n",
      "After duplicate detection found 197 cards\n",
      "Found 198 cards\n",
      "After duplicate detection found 198 cards\n"
     ]
    }
   ],
   "source": [
    "carter_df = to_df(CARTER_KEY, verbose=True)\n",
    "carter_df = carter_df.rename(columns={'Count': 'Carter Count', 'Level': 'Carter Level'})\n",
    "\n",
    "chris_df = to_df(CHRIS_KEY, verbose=True)\n",
    "chris_df = chris_df.rename(columns={'Count': 'Chris Count', 'Level': 'Chris Level'})\n",
    "\n",
    "dad_df = to_df(DAD_KEY, verbose=True)\n",
    "dad_df = dad_df.rename(columns={'Count': 'Dad Count', 'Level': 'Dad Level'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing out Scraped Data to an Excel File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_xls(list_dfs, df_names, xls_path):\n",
    "    with ExcelWriter(xls_path) as writer:\n",
    "        for name, df in zip(df_names, list_dfs):\n",
    "            df.to_excel(writer, name)\n",
    "        writer.save()\n",
    "\n",
    "time_now = str(datetime.datetime.now())[:10]\n",
    "save_xls([carter_df, chris_df, dad_df], [\"carter_df\", \"chris_df\", \"dad_df\"], \"./clash_royale{}.xlsx\".format(time_now))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trading Algorithm\n",
    "\n",
    "- Preference Variables\n",
    "    - Current level (maybe surplus)\n",
    "    - Overall Popularity in the legendary arena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_reader(player):\n",
    "    return pd.read_excel('./clash_royale.xlsx', sheet_name='{}_df'.format(player))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_joint(player_1, player_2):\n",
    "    player_1_df, player_2_df = df_reader(player_1), df_reader(player_2)\n",
    "    joint_df = pd.merge(player_1_df, player_2_df, left_on='Name', right_on='Name')\n",
    "    del joint_df['Rarity_x']\n",
    "    joint_df = joint_df.rename(columns={'Rarity_y' : 'Rarity'})\n",
    "    joint_df = joint_df.drop_duplicates()\n",
    "    joint_df['Level Diff'] = joint_df['{} Level'.format(player_1.title())].astype(int) -\\\n",
    "        joint_df['{} Level'.format(player_2.title())].astype(int)\n",
    "    return joint_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trades(joint_df, rarity, diff):\n",
    "    joint_df = joint_df[(joint_df['Rarity'] == rarity) & (joint_df['Name_x'] == joint_df['Name_y'])]\n",
    "    _1 = joint_df.loc[(joint_df[\"Level Diff\"] == -1*diff)]\n",
    "    _2 = joint_df.loc[(joint_df[\"Level Diff\"] == diff)]\n",
    "    return _1, _2\n",
    "\n",
    "def get_rarity(joint_df, rarity):\n",
    "    return joint_df[(joint_df['Rarity'] == rarity)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carter_and_dad = get_joint('carter', 'dad')\n",
    "chris_and_dad = get_joint('chris', 'dad')\n",
    "carter_and_chris = get_joint('carter', 'chris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rarity(carter_and_dad, \"Epic\").sort_values('Level Diff')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
