{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from pandas import ExcelWriter, DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "CARTER_KEY = \"PVQ90YCV\"\n",
    "CHRIS_KEY = \"2JV9RJYJG\"\n",
    "DAD_KEY = \"L8RCCJGV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return parsed profile page using BS4\n",
    "def parseURL(tag, sort_by):\n",
    "    if sort_by == \"level\":\n",
    "         link = \"https://statsroyale.com/profile/{}/cards?sort=level\".format(tag)\n",
    "    elif sort_by == \"elixir\":\n",
    "        link = \"https://statsroyale.com/profile/{}/cards?sort=exlixir\".format(tag)\n",
    "    elif sort_by == \"rarity\":\n",
    "        link = \"https://statsroyale.com/profile/{}/cards?sort=rarity\".format(tag)\n",
    "    elif sort_by == \"arena\":\n",
    "        link = \"https://statsroyale.com/profile/{}/cards?sort=arena\".format(tag)\n",
    "    \n",
    "    response = requests.get(link).text\n",
    "    soup = BeautifulSoup(response, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Card:\n",
    "    def __init__(self, card_html):\n",
    "        self.name, self.level, self.curr_count, self.rarity = self.parse(card_html)\n",
    "    \n",
    "    def parse(self, card_html):\n",
    "        rarity_map = {\n",
    "            \"1\" : \"Common\", \n",
    "            \"2\" : \"Rare\",\n",
    "            \"3\" : \"Epic\",\n",
    "            \"4\" : \"Legendary\"\n",
    "        }\n",
    "        name = card_html.find(\"div\", {\"class\" : \"ui__tooltip ui__tooltipTop ui__tooltipMiddle cards__tooltip\"}).text.replace('\\n','')\n",
    "        level = card_html.find(\"a\").text.replace('\\n','')\n",
    "        curr_count = card_html.find(\"div\", {\"class\" : \"profileCards__meter__numbers\"}).text.replace('\\n','')\n",
    "        rarity = card_html[\"data-rarity\"][0]\n",
    "        return name, level, curr_count, rarity_map[rarity]\n",
    "    \n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"{}\".format(self.name)\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(self.name)\n",
    "\n",
    "    def to_row(self):\n",
    "        return {\"Name\" : self.name, \"Level\": self.level, \"Count\" : self.curr_count, \"Rarity\" : self.rarity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_df(key, verbose=False):\n",
    "    carter_soup = parseURL(key, \"rarity\")\n",
    "    carter_cards_html = carter_soup.findAll(\"div\", {\"class\": \"profileCards__card upgrade \"}) + \\\n",
    "                        carter_soup.findAll(\"div\", {\"class\": \"profileCards__card \"}) + \\\n",
    "                        carter_soup.findAll(\"div\", {\"class\": \"profileCards__card upgrade\"}) + \\\n",
    "                        carter_soup.findAll(\"div\", {\"class\": \"profileCards__card\"})\n",
    "\n",
    "    carter_card_objs = [Card(card_html) for card_html in carter_cards_html]\n",
    "    if verbose:\n",
    "        print(\"Found {} cards\".format(len(carer_cards_objs)))\n",
    "        \n",
    "    try:\n",
    "        assert len(carer_cards_objs) == len(set(carter_cards_objs))\n",
    "    except AssertionError:\n",
    "        print(\"Duplicate Cards Detected and removed\")\n",
    "        carter_card_objs = list(set(carer_cards_objs))\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"After duplicate detection found {} cards\".format(len(carter_card_objs)))\n",
    "\n",
    "    carter_cards = [card_obj.to_row() for card_obj in carter_card_objs]\n",
    "    df = DataFrame(carter_cards); df.index = df.Name; del df[\"Name\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 196 cards\n",
      "After duplicate detection found 196 cards\n",
      "Found 196 cards\n",
      "After duplicate detection found 196 cards\n",
      "Found 196 cards\n",
      "After duplicate detection found 196 cards\n"
     ]
    }
   ],
   "source": [
    "carter_df = to_df(CARTER_KEY, verbose=True)\n",
    "chris_df = to_df(CHRIS_KEY, verbose=True)\n",
    "dad_df = to_df(DAD_KEY, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_xls(list_dfs, df_names, xls_path):\n",
    "    with ExcelWriter(xls_path) as writer:\n",
    "        for name, df in zip(df_names, list_dfs):\n",
    "            df.to_excel(writer, name)\n",
    "        writer.save()\n",
    "\n",
    "save_xls([carter_df, chris_df, dad_df], [\"carter_df\", \"chris_df\", \"dad_df\"], \"./clash_royale.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
